# analyze_macro_awareness_final.py
import pickle as pkl
import pandas as pd
import numpy as np
import os

# ==================== é…ç½® ====================
class DummyUnpickler(pkl.Unpickler):
    def find_class(self, module, name):
        if 'ai_economist' in module:
            return type(name, (), {})
        return super().find_class(module, name)

BASE = "/workspace/QWEN2.5_FEWSHOT/data"
MODEL = "gpt-3-noperception-reflection-1-100agents-240months"
DATA = os.path.join(BASE, MODEL)
OUT = os.path.join(DATA, "fewshot_analysis")
os.makedirs(OUT, exist_ok=True)

# ==================== åŠ è½½æ•°æ® ====================
print("ğŸ“‚ åŠ è½½dense_log...")
dense_log_path = os.path.join(DATA, "dense_log.pkl")

with open(dense_log_path, "rb") as f:
    dense_log = DummyUnpickler(f).load()

print("âœ… æ•°æ®åŠ è½½æˆåŠŸ")

# ==================== æå–æ•°æ® ====================
print("\nğŸ“Š æå–agentå†³ç­–å’Œå®è§‚æŒ‡æ ‡...")

states = dense_log['states']
actions = dense_log['actions']

n_agents = len([k for k in states[0].keys() if k != 'p'])
n_timesteps = len(states)

print(f"  Agents: {n_agents}")
print(f"  Timesteps (states): {n_timesteps}")
print(f"  Timesteps (actions): {len(actions)}")

# æ­£ç¡®æå–ï¼šactionæ˜¯å­—å…¸ {'SimpleLabor': 0/1, 'SimpleConsumption': 0-50}
agent_consumption = {i: [] for i in range(n_agents)}
agent_work = {i: [] for i in range(n_agents)}

for t, action in enumerate(actions):
    for i in range(n_agents):
        agent_id = str(i)
        if agent_id in action:
            agent_action = action[agent_id]
            
            # æå–å·¥ä½œå†³ç­–
            work_decision = agent_action.get('SimpleLabor', 0)
            
            # æå–æ¶ˆè´¹å†³ç­–
            consumption_idx = agent_action.get('SimpleConsumption', 0)
            consumption_prop = consumption_idx * 0.02  # è½¬æ¢ä¸ºæ¯”ä¾‹
            
            agent_work[i].append(work_decision)
            agent_consumption[i].append(consumption_prop)
        else:
            agent_work[i].append(0)
            agent_consumption[i].append(0)

print(f"âœ… æå–å®Œæˆ")
print(f"  Agent 0çš„å†³ç­–æ•°: {len(agent_work[0])}")
print(f"  Agent 0å‰5ä¸ªworkå†³ç­–: {agent_work[0][:5]}")
print(f"  Agent 0å‰5ä¸ªconsumptionå†³ç­–: {[f'{c:.2f}' for c in agent_consumption[0][:5]]}")

# éªŒè¯æ•°æ®
total_work_decisions = sum([sum(agent_work[i]) for i in range(n_agents)])
total_consumption = sum([sum(agent_consumption[i]) for i in range(n_agents)])

print(f"\nâœ… æ•°æ®éªŒè¯:")
print(f"  æ€»å°±ä¸šå†³ç­–æ¬¡æ•°: {total_work_decisions}")
print(f"  å¹³å‡æ¯æœˆå°±ä¸šäººæ•°: {total_work_decisions/len(actions):.1f}")
print(f"  æ€»æ¶ˆè´¹é‡‘é¢: {total_consumption:.0f}")

# è®¡ç®—å®è§‚æŒ‡æ ‡
print("\nğŸ“Š è®¡ç®—å®è§‚æŒ‡æ ‡...")

# 1. å¤±ä¸šç‡
unemployment_rate = []
for t in range(len(actions)):
    employed_count = sum([agent_work[i][t] for i in range(n_agents)])
    unemployment_rate.append(1 - employed_count / n_agents)

# 2. å¹³å‡æ¶ˆè´¹å€¾å‘
avg_consumption_prop = []
for t in range(len(actions)):
    consumptions = [agent_consumption[i][t] for i in range(n_agents)]
    avg_consumption_prop.append(np.mean(consumptions))

# 3. GDPå¢é•¿ç‡ï¼ˆç”¨å°±ä¸šç‡ä½œä¸ºGDP proxyï¼‰
gdp_proxy = [1 - ur for ur in unemployment_rate]
gdp_growth = []
for t in range(1, len(gdp_proxy)):
    if gdp_proxy[t-1] > 0:
        growth = (gdp_proxy[t] - gdp_proxy[t-1]) / gdp_proxy[t-1]
        gdp_growth.append(growth)

print(f"âœ… å®è§‚æŒ‡æ ‡è®¡ç®—å®Œæˆ")
print(f"  å¤±ä¸šç‡æ•°æ®ç‚¹: {len(unemployment_rate)}")
print(f"  å¹³å‡æ¶ˆè´¹æ•°æ®ç‚¹: {len(avg_consumption_prop)}")
print(f"  GDPå¢é•¿ç‡æ•°æ®ç‚¹: {len(gdp_growth)}")

# ==================== åŸºæœ¬ç»Ÿè®¡ ====================
print("\n" + "=" * 70)
print("ğŸ“Š å®è§‚æŒ‡æ ‡åŸºæœ¬ç»Ÿè®¡")
print("=" * 70)

print(f"\nå¤±ä¸šç‡:")
print(f"  å‡å€¼: {np.mean(unemployment_rate)*100:.2f}%")
print(f"  ä¸­ä½æ•°: {np.median(unemployment_rate)*100:.2f}%")
print(f"  èŒƒå›´: [{np.min(unemployment_rate)*100:.2f}%, {np.max(unemployment_rate)*100:.2f}%]")

print(f"\nå¹³å‡æ¶ˆè´¹å€¾å‘:")
print(f"  å‡å€¼: {np.mean(avg_consumption_prop):.3f}")
print(f"  ä¸­ä½æ•°: {np.median(avg_consumption_prop):.3f}")
print(f"  èŒƒå›´: [{np.min(avg_consumption_prop):.3f}, {np.max(avg_consumption_prop):.3f}]")

print(f"\nGDPå¢é•¿ç‡:")
print(f"  å‡å€¼: {np.mean(gdp_growth)*100:.2f}%")
print(f"  ä¸­ä½æ•°: {np.median(gdp_growth)*100:.2f}%")
print(f"  æ ‡å‡†å·®: {np.std(gdp_growth)*100:.2f}%")
print(f"  èŒƒå›´: [{np.min(gdp_growth)*100:.2f}%, {np.max(gdp_growth)*100:.2f}%]")

# ==================== ç»æµå‘¨æœŸåˆ†æ ====================
print("\n" + "=" * 70)
print("ğŸ“Š ç»æµå‘¨æœŸåˆ†æ")
print("=" * 70)

# å¯¹é½æ•°æ®
min_len = min(len(gdp_growth), len(avg_consumption_prop) - 1, len(unemployment_rate) - 1)
df_analysis = pd.DataFrame({
    'timestep': range(min_len),
    'gdp_growth': gdp_growth[:min_len],
    'unemployment_rate': unemployment_rate[1:min_len+1],
    'avg_consumption': avg_consumption_prop[1:min_len+1]
})

# å®šä¹‰ç»æµçŠ¶æ€
df_analysis['economic_state'] = 'Normal'
df_analysis.loc[df_analysis['gdp_growth'] < -0.02, 'economic_state'] = 'Recession'
df_analysis.loc[df_analysis['gdp_growth'] > 0.02, 'economic_state'] = 'Boom'

print(f"\nç»æµçŠ¶æ€åˆ†å¸ƒ:")
state_counts = df_analysis['economic_state'].value_counts()
for state, count in state_counts.items():
    print(f"  {state:10s}: {count:3d} ä¸ªæœˆ ({count/len(df_analysis)*100:.1f}%)")

print(f"\nä¸åŒç»æµçŠ¶æ€ä¸‹çš„å¹³å‡æ¶ˆè´¹å€¾å‘:")
consumption_by_state = df_analysis.groupby('economic_state')['avg_consumption'].agg(['mean', 'std', 'count'])
print("\nçŠ¶æ€        å‡å€¼     æ ‡å‡†å·®   æ ·æœ¬æ•°")
print("-" * 45)
for state, row in consumption_by_state.iterrows():
    print(f"{state:10s}  {row['mean']:.3f}   {row['std']:.3f}   {int(row['count']):6d}")

# ==================== å…³é”®é—®é¢˜ï¼šé¡ºå‘¨æœŸ vs é€†å‘¨æœŸ ====================
print("\n" + "=" * 70)
print("ğŸ” å…³é”®é—®é¢˜ï¼šAgentæ˜¯å¦è¿›è¡Œé€†å‘¨æœŸè°ƒæ•´ï¼Ÿ")
print("=" * 70)

# è®¡ç®—ç›¸å…³æ€§
df_analysis['consumption_change'] = df_analysis['avg_consumption'].diff()
df_analysis['gdp_change'] = df_analysis['gdp_growth'].diff()
df_corr = df_analysis[['consumption_change', 'gdp_change']].dropna()

if len(df_corr) > 10:
    correlation = df_corr['consumption_change'].corr(df_corr['gdp_change'])
    print(f"\næ¶ˆè´¹å˜åŒ– vs GDPå¢é•¿å˜åŒ–çš„ç›¸å…³ç³»æ•°: {correlation:.3f}")
    
    if correlation > 0.3:
        print("\n  âš ï¸ æ­£ç›¸å…³ï¼Agentå€¾å‘äºé¡ºå‘¨æœŸæ¶ˆè´¹ï¼ˆåŠ å‰§æ³¢åŠ¨ï¼‰")
        print("     è§£é‡Šï¼š")
        print("     - ç»æµå¥½æ—¶ï¼Œagentå¢åŠ æ¶ˆè´¹ â†’ å¯èƒ½å¯¼è‡´è¿‡çƒ­")
        print("     - ç»æµå·®æ—¶ï¼Œagentå‡å°‘æ¶ˆè´¹ â†’ åŠ å‰§è¡°é€€")
        print("     - Agentç¼ºä¹'é€†å‘¨æœŸè°ƒèŠ‚'èƒ½åŠ›")
    elif correlation < -0.3:
        print("\n  âœ… è´Ÿç›¸å…³ï¼Agentå€¾å‘äºé€†å‘¨æœŸæ¶ˆè´¹ï¼ˆç¨³å®šç»æµï¼‰")
        print("     è§£é‡Šï¼š")
        print("     - ç»æµå¥½æ—¶ï¼Œagentå‡å°‘æ¶ˆè´¹ï¼ˆå‚¨è“„ï¼‰")
        print("     - ç»æµå·®æ—¶ï¼Œagentå¢åŠ æ¶ˆè´¹ï¼ˆåˆºæ¿€ï¼‰")
    else:
        print("\n  â¡ï¸ å¼±ç›¸å…³ã€‚Agentå†³ç­–ä¸å®è§‚å‘¨æœŸå…³ç³»ä¸æ˜æ˜¾")
        print("     è§£é‡Šï¼š")
        print("     - Agentä¼¼ä¹ä¸å…³æ³¨å®è§‚ç»æµçŠ¶æ€")
        print("     - å†³ç­–ä¸»è¦åŸºäºä¸ªäººè´¢å¯Œ/æ”¶å…¥")

# ==================== å…³é”®å‘ç°æ€»ç»“ ====================
print("\n" + "=" * 70)
print("ğŸ” å…³é”®å‘ç°æ€»ç»“")
print("=" * 70)

print("\n1. å®è§‚æ„è¯†ç¼ºå¤±:")
print(f"   - æ¶ˆè´¹-GDPç›¸å…³æ€§: {correlation:.3f}")
if abs(correlation) < 0.2:
    print("   - âš ï¸ Agentå†³ç­–ä¸å®è§‚å‘¨æœŸå‡ ä¹æ— å…³")
    print("   - Agentä¸çŸ¥é“ç»æµåœ¨è¡°é€€è¿˜æ˜¯ç¹è£")

print("\n2. ç»æµå‘¨æœŸ:")
è¡°é€€æ¯”ä¾‹ = (df_analysis['economic_state'] == 'Recession').sum() / len(df_analysis)
ç¹è£æ¯”ä¾‹ = (df_analysis['economic_state'] == 'Boom').sum() / len(df_analysis)
print(f"   - è¡°é€€æœŸå æ¯”: {è¡°é€€æ¯”ä¾‹*100:.1f}%")
print(f"   - ç¹è£æœŸå æ¯”: {ç¹è£æ¯”ä¾‹*100:.1f}%")

print("\n3. ä¸ºä»€ä¹ˆç¬¦å·ä¸€è‡´æ€§åªæœ‰31.58%:")
print("   - Agentåªèƒ½çœ‹åˆ°è‡ªå·±çš„å¾®è§‚çŠ¶æ€ï¼ˆæ”¶å…¥ã€è´¢å¯Œï¼‰")
print("   - æ— æ³•è·å–å®è§‚ä¿¡å·ï¼ˆæ•´ä½“å¤±ä¸šç‡ã€é€šèƒ€ã€GDPï¼‰")
print("   - ç¼ºä¹'é¢„è§æ€§'ï¼Œåªèƒ½'ååº”æ€§'å†³ç­–")
print("   - ç»“æœï¼šæ— æ³•é¢„æµ‹ç»æµå¢é•¿/è¡°é€€æ–¹å‘")

print("\n4. æ”¹è¿›å»ºè®®:")
print("   a) åœ¨promptä¸­æ³¨å…¥å®è§‚ä¿¡å·")
print("   b) æä¾›'ç»æµå­¦å®¶å»ºè®®'ï¼ˆåŸºäºå®è§‚çŠ¶æ€ï¼‰")
print("   c) è®©agentçŸ¥é“'ç°åœ¨æ˜¯è¡°é€€/ç¹è£æœŸ'")

# ==================== ä¿å­˜ç»“æœ ====================
result_path = os.path.join(OUT, "macro_awareness_summary.csv")
with open(result_path, 'w') as f:
    f.write("metric,value\n")
    f.write(f"avg_gdp_growth,{np.mean(gdp_growth)}\n")
    f.write(f"std_gdp_growth,{np.std(gdp_growth)}\n")
    f.write(f"avg_unemployment,{np.mean(unemployment_rate)}\n")
    f.write(f"avg_consumption_prop,{np.mean(avg_consumption_prop)}\n")
    f.write(f"consumption_gdp_correlation,{correlation}\n")
    f.write(f"n_recession_periods,{(df_analysis['economic_state']=='Recession').sum()}\n")
    f.write(f"n_boom_periods,{(df_analysis['economic_state']=='Boom').sum()}\n")
    f.write(f"recession_ratio,{è¡°é€€æ¯”ä¾‹}\n")
    f.write(f"boom_ratio,{ç¹è£æ¯”ä¾‹}\n")

print(f"\nâœ… ç»“æœå·²ä¿å­˜: {result_path}")

print("\n" + "=" * 70)
print("âœ… å®è§‚æ„è¯†åˆ†æå®Œæˆï¼")
print("=" * 70)